{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059b071c-9dbd-4b57-8695-e89181ac283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwertyenv.collect_coins_pz import CollectCoinsEnv\n",
    "from qwertyenv.pz_to_gymnasium_wrapper import PZ2GymnasiumWrapper\n",
    "from qwertyenv.ensure_valid_action_pz import EnsureValidAction\n",
    "# import gym\n",
    "import qwertyenv\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import tianshou\n",
    "from tianshou.data import Collector\n",
    "from tianshou.env import DummyVectorEnv\n",
    "\n",
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3.ppo.policies import MlpPolicy, MultiInputPolicy\n",
    "# from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f52a55-7d45-4999-b26b-7eb5f42ddd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04497409-cc55-4ada-9bbd-7eb4de8c6b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = None\n",
    "\n",
    "# env =  gym.make('qwertyenv/CollectCoins-v0', pieces=['rock', 'rock'])\n",
    "\n",
    "pz_env = CollectCoinsEnv(pieces=['rock', 'rock'], with_mask=True)\n",
    "\n",
    "def another_action_taken(action_taken):\n",
    "    global action\n",
    "    action = action_taken\n",
    "\n",
    "# Wrapping the original environment as to make sure a valid action will be taken.\n",
    "pz_env = EnsureValidAction(\n",
    "  pz_env,\n",
    "  pz_env.check_action_valid,\n",
    "  pz_env.provide_alternative_valid_action,\n",
    "  another_action_taken\n",
    ")\n",
    "\n",
    "def act_player_1(obs):\n",
    "    return (0, 0)\n",
    "\n",
    "gym_env = PZ2GymnasiumWrapper(pz_env, act_others={'player_1': act_player_1})\n",
    "\n",
    "policy = tianshou.policy.RandomPolicy()\n",
    "# agent_w = PPO(MultiInputPolicy, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16581763-2e3e-4b3e-9a01-10a30e9cecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(num_episodes: int = 1):\n",
    "\n",
    "  seed = 1\n",
    "    \n",
    "  # ======== environment setup =========\n",
    "  train_envs = DummyVectorEnv([lambda: gym_env])\n",
    "  test_envs = DummyVectorEnv([lambda: gym_env])\n",
    "  # seed\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  train_envs.seed(seed)\n",
    "  test_envs.seed(seed)\n",
    "    \n",
    "  policy.eval()\n",
    "  # pdb.set_trace()\n",
    "  test_collector = Collector(policy, test_envs, exploration_noise=False)\n",
    "\n",
    "\n",
    "\n",
    "  result = test_collector.collect(n_step=10000, render=False) # n_episode=num_episodes,\n",
    "    \n",
    "  print(result['rew'])\n",
    "    \n",
    "    # test_collector = Collector(policy, self.test_envs, exploration_noise=False)\n",
    "    # for episode in range(num_episodes):\n",
    "    #     print(f'{episode=}')\n",
    "    #     print(\"-------\")\n",
    "    #     obs, info = env.reset(seed=1)\n",
    "    #     obs = obs[()]\n",
    "    #     env.render()\n",
    "    #     while True:\n",
    "    #       action, _state = policy.forward({'obs': obs}) #  agent_w.predict(obs, deterministic=True)\n",
    "    #       # print(f'action predicted: {action}')\n",
    "    #       obs, reward, done, info = env.step(action)\n",
    "    #       # print(f'action taken: {action}')\n",
    "    #       env.render()\n",
    "    #       print()\n",
    "    #       print(f'{reward=}, {done=}, {info=}')\n",
    "    #       print()\n",
    "    #       if done:\n",
    "    #         break\n",
    "    #     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea2fb13-04a5-4f18-af0a-c8975463413f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2274000000000001\n"
     ]
    }
   ],
   "source": [
    "play(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afe41c6a-4c8f-4ebc-b5c6-4d3082c97ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: agent_w.learn(total_timesteps=int(2e5), progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "865b5b90-5bc2-4b83-8211-d31116de88f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18340000000000006\n"
     ]
    }
   ],
   "source": [
    "play(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "039b529c-4ecb-49e2-af83-bfb0abc80f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: mean_reward, std_reward = evaluate_policy(agent_w, env, deterministic=True)\n",
    "# print(f'{mean_reward=}, {std_reward=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c45e66d-bddd-4929-9ae7-f86bc6380ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
